[{"title":"Hello World","path":"/2023/04/08/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment"},{"title":"LLaMA 套件踩坑","path":"/2023/04/07/20230407/","content":"本文介紹 LLaMA 系列套件安裝踩過的一些坑和解法 bitsandbytes load_in_8bit error Root Cause: 系統預設的 bitsandbytes_cpu.so 與 cuda 版本不同 Action: 將自己的版本的 bitsandbytes_cuda&lt;cuda版號&gt;.so 替換為 bitsandbytes_cpu.so step1: mv lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cpu.so lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cuda114.so step2: cp lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cuda117.so lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cpu.so transformer 目前僅有 transformers-main 的版本支援 LlamaTokenizer 系列的子套件 12pip uninstall transformerspip install git+https://github.com/huggingface/transformers.git pytorch docker LLaMA 最低 python 環境要求為 python 3.8, 如何的套用現成 Docker Image? 以下是 pytorch 在 dockerhub 各版本對應到的 python 環境:","tags":["practice"],"categories":["NLP"]}]