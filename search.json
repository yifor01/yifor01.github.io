[{"title":"Vicuna 完整安裝手冊","path":"/2023/05/01/20230501/","content":"本文介紹 Vicuna 模型安裝踩過的一些坑和解法, 實作使用 transformers==4.28.1 Step 1: 下載 LLaMA weight 填寫Meta 申請表格 此方法試過沒成功 使用 pyllama 下載 安裝套件 pip install pyllama -U 下載所有版本(7B, 13B, 30B, 65B)的 LLaMA weight python -m llama.download --model_size 7B,13B,30B,65B --folder ~/pyllama_data 此方法下載的 model 不可用 transformers 來 load, 必須透過 transformers 內建的轉換腳本轉換 python -m transformers.models.llama.convert_llama_weights_to_hf --input_dir ~/ --model_size &#123;13B&#125; --output_dir ~/huggingface_llama_&#123;13B&#125;/ (推薦) 下載別人壓好 huggingface 格式的 model huggingface: decapoda-research/llama-7b-hf Step 2: 加入 Lora 或 Delta weight 主流的方法使採用 LORA 的方式來訓練 weight (Wtarget=Winit+ΔWW_{target}=W_{init}+\\Delta WWtarget​=Winit​+ΔW, 只訓練 ΔW\\Delta WΔW) 透過 fastchat 提供的轉換腳本將權重轉換 python -m fastchat.model.apply_delta --base ~/huggingface_llama_&#123;13B&#125;/ --target ~/vicuna_&#123;13B&#125;/ --delta lmsys/vicuna-13b-delta-v1.1 載入程式碼如下: 12345678from transformers import LlamaForCausalLM model = LlamaForCausalLM.from_pretrained( &quot;~/vicuna_&#123;13B&#125;&quot;, load_in_8bit=True, device_map=&quot;auto&quot;, torch_dtype=torch.float16) 若為 LORA MODEL, 透過 peft 套件來載入, 載入程式碼如下 12345678910111213from transformers import LlamaForCausalLMfrom peft import PeftModel model = LlamaForCausalLM.from_pretrained( &quot;decapoda-research/llama-7b-hf&quot;, device_map=&quot;auto&quot;, torch_dtype=torch.float16)lora_model = PeftModel.from_pretrained(model, LORA_MODEL_NAME, device_map=&#x27;auto&#x27;)model = lora_model.merge_and_unload() 若為 DELTA MODEL, 透過 transformers 套件來載入, 載入程式碼如下 1234567891011121314151617181920from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfigmodel = LlamaForCausalLM.from_pretrained( &quot;decapoda-research/llama-7b-hf&quot;, load_in_8bit=False, device_map=&quot;auto&quot;, torch_dtype=torch.float16, low_cpu_mem_usage=True)delta_model = LlamaForCausalLM.from_pretrained( &quot;lmsys/vicuna-7b-delta-v1.1&quot;, load_in_8bit=False, device_map=&quot;auto&quot;, torch_dtype=torch.float16, low_cpu_mem_usage=True) for name, param in model.state_dict().items(): param.data += delta_model.state_dict()[name] Step 3: 預測 GPT 預測原理就是找出下一個字的最高機率值, 但如果每次都使用最高機率值的字會讓結果缺乏多樣性或是讓預測結果歪掉, 所以會建立一套 sampling 機制來處理輸出 next token prediction 常用參數說明: do_sample: 預測結果是否做 sampling, 一般要讓 LLM 具有輸出多樣性都會設定為 True temperature: 控制字詞多元性, 值越高生成結果越有隨機性 temperature 比較 top_k: 保留最大的 k 個字詞作抽樣, 其餘不考慮 top_k 比較 top_p: 保留前 n 個機率值相加&lt; top_p 的字, 用法類似 top_k top_k 比較 repetition_penalty: 懲罰重複出現的字詞 (降低出現機率值) 預測程式碼 12345678910111213141516171819202122232425from transformers import LlamaTokenizertokenizer = LlamaTokenizer.from_pretrained(&quot;lmsys/vicuna-7b-delta-v1.1&quot;)prompt = &quot;台灣小吃淡水阿給是怎麼做的?&quot; inputs = tokenizer(prompt,return_tensors=&quot;pt&quot;)input_ids = inputs[&quot;input_ids&quot;].cuda()generation_config = GenerationConfig( do_sample=False, temperature=0.9, top_p=0.65, num_beams=1, repetition_penalty=1.15 , length_penalty=-0.25)generation_output = model.generate( input_ids=input_ids, generation_config=generation_config, return_dict_in_generate=True, output_scores=True, max_new_tokens=100)print(tokenizer.decode(generation_output.sequences[0])) Reference A step-by-step guide to running Vicuna-13B Large Language Model on your GPU / CPU machine pyllama github LLM hyperparameters LLM hyperparameters","tags":["practice"],"categories":["NLP"]},{"title":"Improving Implicit Sentiment Learning via Local Sentiment Aggregation","path":"/2023/04/11/20230411/","content":"本文為 “Improving Implicit Sentiment Learning via LSA” (2021.10) 的論文重點摘要 論文全文參考 (強烈建議 v1, v2版本一起閱讀) Improving Implicit Sentiment Learning via LSAhttps://arxiv.org/abs/2110.08604 Demo 參考 ABSA Quadruple Extractionhttps://huggingface.co/spaces/Gradio-Blocks/Multilingual-Aspect-Based-Sentiment-Analysis Description Goal 2022年 ABSC 的 SOTA model (SemEval-2014 Task 4 - Subtask 2) ABSA/ABSC 任務 (Aspect Based Sentiment Analysis/Classification) 根據資料集的定義, 這任務又細分為兩類 Aspect term polarity 和 Aspect category polarity Aspect term polarity: 對已經提供的 term 進行情感分類。 Example: I hated their fajitas, but their salads were great → {fajitas: negative, salads: positive} Aspect category polarity: 對抽象概念 aspect 進行情感分類。 Example: The restaurant was too expensive → {price: negative} 此篇論文討論的 ABSC 問題是屬於 Aspect term polarity 類的。 Contributions 非句法樹結構方法優於句法樹(syntax tree)方法。 實驗中比較了數個 syntax-based 的方法在不同的資料集上, 如: SK-GCN-BERT (2020), DGEDT-BERT (2020), ASGCN-RoBERTa (2021), SARL-RoBERTa (2021) 等等。 syntax tree 有個比較大的問題是 syntax 切出來的 token, 會與 BERT token 有 alignment issue。 此篇論文 propose 的方法 $LSA_{T}-X-DeBERTa$, $LSA_{S}-X-DeBERTa$ 均優於上面 syntax-based 方法約 2-8% 的 F1 score。 (X 代表是 large 模型) syntax tree example LSA (Local Sentiment Aggregation) 是 ABSC 的通用泛式。 實驗中抽換了 pre-train model (BERT, RoBERTa, DeBERTa) 對於結果都有較顯著的改進 0.5%-1%。因此作者認為 LSA 具有一定的擴展性和靈活性。 LSA 是一種通用的架構用來捕捉 aspect 附近的 local sentiment, 分別提取出 aspect feature, 底下會介紹相關細節。 差分加權策略 → 使 LSA 可以用 gradient descent 來優化相鄰情感值。 此策略主要是用在多個 aspect 使用的, 兩個 aspect 中間的子句在計算 aspect feature 時會同時受到影響, 此時就乘上一個 weight $\\eta^L$, $\\eta^R$ 來自動訓練出哪個 aspect 影響比較大。 Methodology Sentiment Pattern 作者觀察了五個著名的 ABSC 資料集, 歸納出情感具有 cluster 特性, 因此有了提取相鄰情感的想法 (Sentiment Coherency)。 相鄰情感可以處理更進階的隱式情感, 並可以消除因為部分噪音文字造成的分類錯誤問題。 此例子中有兩個 sentiment cluster Local Sentiment Aggregation (LSA) LSA 使用了 sentiment aggregation window 用來抽取上述的相鄰情感 具體用了三個 local sentiment feature representation $LSA_P$: BERT-SPC based feature 將 aspect 嵌在句子後面, 利用 BERT 原本就有注意力模組來提取 aspect feature Example: CLS text SEP aspect SEP BERT-SPC based feature $LSA_T$: Local content focus (LCF) based feature 計算 token 和 aspect 的相對距離來獲取 aspect feature 詳細計算方式定義${W_1^C,W_2^C,…,W_n^C}$ 為 token 序列$H^C_{w_i^C}$ (要學的向量) 為每個 token 位置的 hidden state$d_{w_i^C}$ (定值) 為 token $W_i^C$ 與 aspect 的距離$\\alpha$ (超參數) 為距離的 threshold, 通常訂為 3$H^*_{w_i^C}$: aspect feature計算方式token 與 aspect 較近的時候 ($d_{w_i^C}&lt;\\alpha$), aspect feature 就是當下的 $H^C_{w_i^C}$token 與 aspect 較遠的時候 ($d_{w_i^C}\\geq\\alpha$), aspect feature 會乘距離懲罰項 $(1-\\frac{d_{w_i^C}-\\alpha}{n})$$d_{w_i^C}$ 距離計算為所有的 aspect 和 token $w_i^C$ 平均絕對值距離 $LSA_S$: Syntactical local context focus (LCFS) based feature 距離計算改為 syntax-tree 中每個 token 到 aspect 的最短距離 詳細計算方式計算方式$H^*_{w_i^C}$ 計算方式與 $LSA_T$ 相同$d_{w_i^C}=\\frac{\\sum_{i=j}^mdist(w_i^C,w_j^a)}{m}$ Sentiment Aggregation Window Sentiment Aggregation Window 拼接了 aspect 附近的 aspect feature (left, right, text indices) Aggregation Window Padding 拼接的時候會遇到一個狀況是剛好 aspect 位於句子邊界的情況, 作者使用了 copy 的方式做 padding 而非傳統補空值的方法。 Example 無左右兩邊界: $\\left[null,H^t,null\\right]$ → $\\left[H^t,H^t,H^t\\right]$ 無右邊界: $\\left[H^L,H^t,null\\right]$ → $\\left[H^L,H^t,H^t\\right]$ Differential Weighted Aggregation 當有多個 aspect 時, 會遇到共用子句的狀況這時候計算 aspect feature 會有衝突, 這種時候就會用 $\\eta^_l$ 和 $\\eta^_r$ 分別代表左右 aspect feature 的加權值。 Aggregated hidden state $$H^o_{dwa}=\\left[\\eta^_l{H^l_k};H^t;\\eta_r^{H_k^r}\\right]$$ Conclusion 此篇論文提出一個藉由 LSA 的方法來提取 local sentiment, 在多個 dataset 應證此方法的有效性。 在 $LSA_S$ 中使用了 syntax-tree 的架構, 由於上面提到的 token alignment 問題, 作者不建議使用。 此篇論文有個比較不直觀的地方是左右 aspect feature, 作者有實驗了去除和保留的差異, 如下表: Aggregating Window 架構比較","tags":["paper study"],"categories":["NLP"]},{"title":"Deep Natural Language Processing for LinkedIn Search","path":"/2023/04/09/20230409/","content":"本文為 “Deep Natural Language Processing for LinkedIn Search” (2021.08) 的論文重點摘要 論文全文參考 Deep Natural Language Processing for LinkedIn Searchhttps://arxiv.org/abs/2108.13300 Description Goal 討論在搜尋引擎的 5+1 項 NLP 任務實務上的作法 在重視延遲問題的搜尋任務上, 如何導入 BERT 三大挑戰 延遲性：搜尋引擎最重要的問題之一。 穩定性：這邊主要是提到 DL overfit 的問題。 有效性：找出適用各種任務的最佳解法, 可能是 rule base 或 DL model。 Search system overview 大致流程為: User 輸入搜尋句 → 檢查搜尋句完整性 → 判斷搜尋意圖 → 找尋相關候選文章 → 輸出相關候選文章排序 六大搜尋任務 六大任務概覽 Query Intention Prediction Goal: 判斷 User 搜尋的目的是屬於哪一個既有標籤分類 (7類) NLP task: Text Classification Difficulty: 搜尋內容比一般文章來的短造成更嚴重的歧義問題 Example: michael dell (person names), dell engineer jobs (company) Solution (short-term) Method: 使用 TextCNN 的作法, backbone 使用了 GloVe 作為 embedding, 並結合了手工特徵(用戶行為, 文章統計, search log) Finding 不用手工特徵, 準確度掉了 0.4% LSTM 雖然準度有提升 0.2%, 但延遲率較 CNN 增加了 0.5ms CNN based query intent prediction Solution (long-term) Method: 將 backbone 換成 LiBERT (Linkedin BERT) Finding 準確度較 CNN 提升了 3.28%, 但沒有比較延遲率的結果 Query Tagging Goal: 抓出 query 中包含的 entity NLP task: NER Difficulty: entity 有嵌套以及歧異的問題 Example: research scientist (title), research (skill), scientist (title) Solution Feature: 分為 char based, word based, lexicon base Method: 使用 semi-markov conditional random f ield (SCRF) Finding: 由於 query 本身已經很短了, 還要再從中抽取 entity 導致大多 DL 模型效果不如建立辭典的方式 (lexicon) Document Ranking Goal: 給定 Query, 從一堆文章找出相關度排序 NLP task: Semantic Textual Similarity Difficulty: 延遲性 &amp; 持續有效性 Solution Method Step 1: 提取 Query 和一份文檔有多個區塊 embedding Step 2: 計算 Query embedding 和各區塊 embedding 的 cos similarity Step 3: 將 cos 特徵和手工特徵 concat 起來 Step 4: 建立 learning-to-rank layer 來計算此文檔的分數 模型架構 (不包含 learning-to-rank layer) Supplementary learning-to-rank layer Reference：Neural Ranking Models with Multiple Document Fields Sign: $\\Psi$ : matching netword $\\Lambda_D$ : 集成 D 文檔的各區塊 $\\Phi_Q$ : query representation $\\Phi_D$ : doc representation $\\Phi_F$ : D 文檔的各個 field representation $D$ 文檔的檢索分數 $$\\Psi(\\Phi_Q,\\Phi_D)=\\Psi(\\Phi_Q,\\Lambda_D(\\Phi_{F1}(F1),\\Phi_{F2}(F2),…,\\Phi_{Fk}(Fk)))$$ ranking model 架構 Finding: 手工特徵是在個任務的實驗上屬於強力特徵。個人抱持懷疑的態度，畢竟驗證指標使用的是 NDCG, 而非衡量文章相似度作為指標。 Query Auto Completion Goal: 在 user 輸入關鍵字的時, 同時推薦可能想輸入的候選字 NLP task: Language Generation Difficulty: 延遲性 Solution Candidate Generation 對於過往出現過的關鍵詞, 可以用記憶體存取的方式直接讀取 對於未出現的關鍵詞, 採用啟發式的方式產生候選字 啟發式結果可以從三個方式去得 一定時間內, 同個 session 接續查詢的 query (水平) 同用戶輸入的兩個 query 有 co-word (垂直) 不同用戶兩個 query 同時出現 Reference: Mitra and Craswell (2015) Candidate Ranking LSTM 計算後面要接龍字的分數值 query auto completion 架構 (不包含 learning-to-rank layer) Query Suggestion Goal: 在搜尋結束時, 給予 user 下個搜尋字推薦, 類似推薦文章的想法 NLP task: Machine Translation (Seq2Seq) Difficulty: 延遲性, 穩定性 Solution seq2seq model Finding 此任務也可以用來做 query rewrite, 也許可以避免一些 user query 的冷門字 Example: software developer → software engineer BERT Pretrained Goal: 訓練基於自己 domain 的 BERT model NLP task: Eembedding Difficulty: 延遲性 Solution 收集自有的 domain data 使用輕量的 BERT 架構 (12層 → 6層), 以利加快推論速度 Conclusion 依據任務 &amp; 資料特性決定要使用甚麼樣的 model, 不一定都要套用 DL model 文中指出在 Query Tagging 和 Query Auto Completion (seen) 上 DL model 沒有 benefit 對於延遲性的建議 重新設計算法 (e.g., query auto completion) 平行計算 (e.g., query suggestion) Embedding pre-sum (e.g., document ranking) Two stage ranking (e.g., document ranking) 對於穩定性的建議 Check training data, 剔除高度相似的資料 Reuse 手工特徵, 這邊指的是避免過度依賴文字相關的結果","tags":["paper study"],"categories":["NLP"]},{"title":"Meta Segment Anything","path":"/2023/04/08/20230408/","content":"本文介紹 Meta FAIR 新出的套件 segment-anything 的實作方法 &amp; 結果 Demo 網站 https://segment-anything.com/https://segment-anything.com/ Description Goal 自動化 segment 任務 (zero shot), 並可以根據 prompt (point, box, text) 進行調整 Data SA-1B: 高達 11M 張圖片, 1.1B 個 mask 結果 (由 SAM 生成) Result 僅實驗自動化切割功能, 文字 prompt 功能未釋出 插畫自動切割 左圖：原圖 中圖：部分星星沒有被切割出來是因為有設定 threshold 來避免切出太小的物件, 共 109 個區域 右圖：挑選最大面積的 6 個物件顯示 圖片來源: midjourney 產生 Wafer Map 自動切割 左圖：原圖 中圖：部分文字沒有被切割出來是因為有設定 threshold 來避免切出太小的物件, 共 147 個區域 右圖：挑選最大面積的 4 個物件顯示 圖片來源: Development of High Power Green Light Emitting Diode Chips paper SEM Image 自動切割 左圖：原圖 中圖：部分文字沒有被切割出來是因為有設定 threshold 來避免切出太小的物件, 共 32 個區域 右圖：挑選除了 Top1 以外的物件 圖片來源: DLADC: Deep Learning Based Semiconductor Wafer Surface Defects Recognition paper Model Architecture 圖片來源: segment-anything paper Practice Step 1: 模型下載 SAM model 下載 download, 放入 model 資料夾中 123mkdir modelcd modelwget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth Step 2: 讀入權重 import 相關套件 &amp; load model weight 12345678from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictorsam_checkpoint = &quot;./model/sam_vit_h_4b8939.pth&quot;model_type = &quot;vit_h&quot;device = &quot;cuda&quot;sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)sam.to(device=device) Step 3: 載入圖片 用 cv2 載入圖片並轉為 array 形式 123import cv2image = cv2.imread(&#x27;./data/test.png&#x27;)image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) Step 4: 設定模型參數 &amp; 預測 套用 mask 生成器並設定相關參數, 實作後認為 points_per_side, pred_iou_thresh 較為重要。 points_per_side 是控制採樣點的個數, 直接影響到輸出 mask 的質量 pred_iou_thresh 是輸出 mask 機率的 threshold 輸出結果包含了每個 mask 結果的面積大小, bounding box, mask 座標等等。 12345678910mask_generator = SamAutomaticMaskGenerator( model=sam, points_per_side=32, pred_iou_thresh=0.9, stability_score_thresh=0.92, crop_n_layers=1, crop_n_points_downscale_factor=2, min_mask_region_area=100, # Requires open-cv to run post-processing)masks2 = mask_generator.generate(image) Step 5: 顯示分割結果 依照 mask 面積大小排序對原圖進行 mask 著色 12345678910111213141516171819202122import numpy as npimport matplotlib.pyplot as pltdef show_anns(anns): if len(anns) == 0: return sorted_anns = sorted(anns, key=(lambda x: x[&#x27;area&#x27;]), reverse=True) ax = plt.gca() ax.set_autoscale_on(False) for ann in sorted_anns: m = ann[&#x27;segmentation&#x27;] img = np.ones((m.shape[0], m.shape[1], 3)) color_mask = np.random.random((1, 3)).tolist()[0] for i in range(3): img[:,:,i] = color_mask[i] ax.imshow(np.dstack((img, m*0.35)))plt.figure(figsize=(15,15))plt.imshow(image)show_anns(masks2)plt.axis(&#x27;off&#x27;)plt.show() Step 6: 去背結果 建立一個 mask matrix 在乘上原本圖片 matrix 後, 即可得到去背的圖片 123456789101112final_mask = np.zeros(image.shape[:2],dtype=bool)for i in range(len(masks2)): final_mask +=masks2[i][&#x27;segmentation&#x27;]mask_image = image.copy()for i in range(3): mask_image[:,:,i] *=final_maskplt.figure(figsize=(15,15))plt.imshow(mask_image)plt.axis(&#x27;off&#x27;)plt.show()","tags":["practice","Meta"],"categories":["CV"]},{"title":"LLaMA 套件踩坑","path":"/2023/04/07/20230407/","content":"本文介紹 LLaMA 系列套件安裝踩過的一些坑和解法 bitsandbytes load_in_8bit error Root Cause: 系統預設的 bitsandbytes_cpu.so 與 cuda 版本不同 Action: 將自己的版本的 bitsandbytes_cuda&lt;cuda版號&gt;.so 替換為 bitsandbytes_cpu.so step1: mv lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cpu.so lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cuda114.so step2: cp lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cuda117.so lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cpu.so transformer 目前僅有 transformers-main 的版本支援 LlamaTokenizer 系列的子套件 12pip uninstall transformerspip install git+https://github.com/huggingface/transformers.git pytorch docker LLaMA 最低 python 環境要求為 python 3.8, 如何的套用現成 Docker Image? 以下是 pytorch 在 dockerhub 各版本對應到的 python 環境:","tags":["practice"],"categories":["NLP"]},{"path":"/notes/index.html","content":"項目 競賽 2022 玉山人工智慧挑戰賽 - 你說可疑不可疑？ 疑似洗錢交易預測 https://github.com/ansonchang/esun2022https://github.com/ansonchang/esun2022 2021 中鋼人工智慧挑戰賽 - 字元辨識 https://github.com/yifor01/CSC-OCR-competitionhttps://github.com/yifor01/CSC-OCR-competition 2020 I'm the Best Coder Challenge! 2020 https://github.com/yifor01/High-Value-Customer-Forecast-Competitionhttps://github.com/yifor01/High-Value-Customer-Forecast-Competition"},{"path":"/about/index.html","content":"About Me 一位誤入動物園的 NLP 新手, 專長是販賣各種動物周邊 (NLP 建模) 和 Boost 系列跑鞋 (ML 建模)。 Job Experiment NowAI Engineer at TSMCDefect Report 自動化知識抽取模組2022 年 6 月Machine Learning Engineer at Invos既有產品品類多標籤分類模型新品牌、新品類自動化發現模型2022 年 3 月Senior Data Scientist at Wisers專利發表新詞發現算法⾏業專業詞挖掘算法商用 API 開發關鍵詞抽取模組 (包含新詞、熱詞、領域關鍵詞)購買意願模型 (包含中文、廣東話)評論分類模型英文情感分析模型技術研發自動化 POC tagging (支援 8個API, 14個客製化抽取算法)運動品牌知識圖譜優化特定實體的購買意願模型2020 年 2 月Data Scientist at GSSCRM Insight 產品維護 &amp; 新功能開發行銷最佳化 BI公司產品關鍵字廣告成效分析2019 年 7 月"}]