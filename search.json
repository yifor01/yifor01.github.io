[{"title":"RL and Truthfulness – Towards TruthGPT","path":"/2023/06/14/20230613/","content":"本文為 “RL and Truthfulness – Towards TruthGPT” 演講重點摘要, 講者為 John Schulman 影片回播參考 RL and Truthfulness – Towards TruthGPThttps://www.youtube.com/watch?v=hhiLw5Q_UFg Description Goal 避免 model 出現’幻覺’(hallucination) → RLHF &amp; Retrieval 講述自身對於 LLM 的宏觀的看法 Topic 模型為何會產生幻覺? 原理 model 訓練時是以 pattern completion (給出完整答案) 的方式來進行, 這種機制會有 對於不確定的句子, 沒有回答’不知道’的常識 對於前提假設, 不會否決 (認為是統計分布的一部分) 回答出錯誤的資訊, 甚至是進一步的錯誤 第一次嘗試, 並且猜測錯誤 簡易概念 Pre-training model 好比是知識圖譜中的所有節點知識 (node) Fine tuning 就是將節點間的知識作融合 (link) behavior cloning: 透過監督學習的方式微調模型的目的就是要對給定的 prompt 最大化 maximum log likelihood 最大的問題: network 到底學會了那些知識, 這對於後續標註和實驗人員是未知的 透過 behavior cloning 的概念來訓練 model, 如果是不在知識圖譜 node 範圍內的知識, 等於在變相的教 model 產生幻覺 這點在 LLaMA 系列衍生的 model 可以發現這件事情 另一個方面, 如果在 behavior cloning 時, 去教 model 可以回答不知道, 某種狀況下等於在教 model 隱瞞事實 如何預防? Model 知不知道自己在唬爛? 知道, 對於給定的 prompt 下下個字都會有機率分布 可以讓 model 表達這些不確定性, 並給出與輸出機率值類似的結果 (參考 paper: Language Models (Mostly) Know What They Know) John Schulman 認為強化學習是解決幻覺的正解, 但對於 behavior cloning 還是有些小技巧可以嘗試 訓練時告訴模型 (1) ‘我不知道’ (2) ‘我的知識節止於 xx 日期’ (3) 質疑提問的範例 強化學習如何解決幻覺? 訓練 model 的邊界, 這個邊界類似於信心程度 (很有信心的正確答案, 模糊的正確答案, 不知道, 模糊的錯誤答案, 完全錯誤的答案) 為了達到這目標不是一個容易的事, 因為需要知道答案是否正確 小實驗 TriviaQA 是一個流行的問答數據集, 包含了一系列的嘗試問題 (相關資料) 實驗設定是每筆資料都有一個答案, 訓練時都會進行 behavior cloning, 所以都會輸出一個答案 (只有錯誤和正確) 這種監督式學習的方式使用少量數據就能夠達到一定的準確度, 實際上這種方式只是教 model 試圖輸出正確答案, 而沒有交模型太多新的知識, 更多的是回答問題的格式和處理方式 個人觀點: 可以把強化學習當作是學習說話的策略(輸出 threshold), 對於不確定的答案更傾向回答不知道藉此獲得更小的 loss 標註的難題 怎麼標註長文本? 長文本往往發生讓回答處於一種灰色地帶, 部分真實以及部分錯誤, 這種問題對於標註員是一個很困難的問題(也許連標註員都不知道哪部分錯誤) 由於沒有完美的答案, 因此標註的做法轉為去比較各種回答, 對所有的答案進行排序 如何 align model &amp; 標註員認知的正確答案? 新知識注入 動機: 如何引入不在預訓練資料中的訊息(最新事件、私人訊息、聊天紀錄) 如何驗證 model 在唬爛? 人為檢查的依據(來源 &amp; 引用) 應用 - WebGPT 藉由獲取網路的最新資料, 讓 model 參考資料後得出答案並列出來源 webGPT 是使用 GPT3 的 model, 對於最新的 GPT3.5 or GPT4 也許不需要做查詢就能回答出正確答案 由於 model 的文本長度有限制 (4000 個 token), 能夠餵入的參考文章是有限的, 所以透過引用的方式可以保留參考文章訊息並且刪除這些上下文 (???) 應用 - ChatGPT plugin 類似 toolformer 的想法, 詳細的跟 model 說有那些工具 &amp; 接口, 模型會進行相應的操作並產生出’內心獨白’ ChatGPT 只有在不知道答案的情況下去使用瀏覽模式 Conclusion 這篇演講的解釋了 LLM '可能’的運作模式, 以及現在主流的方案存在那些本質上的問題 對於 close domain 領域的資料, 短期內不會有太多新的技術可以考慮 pre-training 讓 model 可以完整地看過所有資料在進行 instruction tuning 對於 open domain 領域的資料, 短期內會有大量新知識可以考慮使用 retrieval 的方式來外掛知識 OpenAI 在解決 model 產生的幻覺花了很大的 effort, 在最新的 [paper](Let’s Verify Step by Step) 也提出了’過程監督’的方法, 讓 model 在訓練過程中把幻覺自動抓出來","tags":["paper study"],"categories":["NLP"]},{"title":"Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca","path":"/2023/05/22/20230522/","content":"本文為 “Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca” (2023.04) 的技術報告重點摘要 論文全文參考 Efficient and Effective Text Encoding for Chinese LLaMA and Alpacahttps://arxiv.org/abs/2304.08177 Open Source Chinese LLaMA and Alpaca Githubhttps://github.com/ymcui/Chinese-LLaMA-Alpaca Description Goal 擴展 LLaMA &amp; Alpaca 模型的應用到中文 在 LLaMA 1.4T tokens 的 pre-train data 中並沒有中文相關的語料 在 LLaMA 的中文 tokenizer 結果是以 bytes 形式來輸出中文 Contributions 開源了一套機制從 LLaMA → Chinese LLaMA → Chinese Alpaca Note: 項目本身是從 LLaMA 轉化而來, 所以 Chinese Alpaca 非商用模型 Methodology LLaMA → Chinese LLaMA Step 0: LLaMA 架構為 embedding layer + transformer block * N + LM head Step 1: 增加中文詞表, 透過 word piece (Google 所提出) 增加中文常用詞, 細節詳見 huggingface 教學 Example (今天去吃午餐) LLaMA: [今,天,去,&lt;0xE5&gt;,&lt;0x90&gt;,&lt;0x83&gt;,&lt;0xE5&gt;,&lt;0x8D&gt;,&lt;0x88&gt;,&lt;0xE9&gt;,&lt;0xA4&gt;,&lt;0x90&gt;] Chinese LLaMA: [今,天,去,吃,午餐] Step 2: 由於對原始 LLaMA 的詞表新增了 20000 個詞, 需要擴增 embedding layer size Step 3: 固定 transformer block, 只訓練 embedding layer, 論文有提到 13B 的模型部用作這部, 個人猜測是 7B 模型不夠大也許會把 transformer block train 壞 Step 4: 對所有 layer 使用 LoRA 繼續 pre-training 的 task 使用 LoRA 的好處是不用 fine-tune 所有 weight, 採用一種擴增的機制來訓練外加的 weight, 這外加的 weight 可以被分解為兩個較小的矩陣相乘, 舉例來說原本要訓練 10000*10000 個參數, 現在透過 10000* {lora rank=8} + {lora rank=8} * 10000 來實現 Chinese LLaMA → Chinese Alpaca Step 1: 仿造 Alpaca 使用 self-instruction 生資料的方式, 並加上額外開源的 QA pair 資料 (e.g., pCLUE, translation, …) Step 2: 調整 instruction data, 用換行符號( )合併原有 Alpaca 的 instruction, input, output 三元組中的 instruction &amp; input Step 3: 使用 LoRA 訓練 instruction training 的 task Training recipes Conclusion 此篇論文實作了中文版本的 LLaMA &amp; Alpaca model, 比較有價值的是開源 code 的部分, 現階段有少數可商用模型 (e.g., OpenLLaMA, MPT) 但訓練資料絕大多數只有英文, 在中文商用模型未釋出的期間利用此方法訓練是一個不錯的選擇 如果要訓練 domain based 的 LLM 勢必要經過 domain 的 tokenizer 去切詞才會事半功倍, 這點在過去 BERT 時代非常常見","tags":["paper study"],"categories":["NLP"]},{"title":"Self-Instruct - Aligning Language Model with Self Generated Instructions","path":"/2023/05/07/20230506/","content":"本文為 “Self-Instruct: Aligning Language Model with Self Generated Instructions” (2022.12) 的論文重點摘要 論文全文參考 Self-Instruct: Aligning Language Model with Self Generated Instructionshttps://arxiv.org/abs/2212.10560 Open Source Self-Instruct Githubhttps://github.com/yizhongw/self-instruct Description Goal 解決 LLM 過度依賴人類標註數據的問題 → 用 LLM 來&quot;半自動&quot;取代, 一種類似 teacher-student 思維 Contributions Stanford Alpaca 是由 LLaMA 7B fine tuning 而來的, 在資料集使用了 OpenAI 的 text-davinci-003 模型基於 self-instruct 產生的 在初始的 GPT3 模型透過 self-instruct 自動化產生資料並訓練後, 與原本的 GPT3 比較性能提升了 33%, 與經由大量標註資料訓練的 InstructGPT_001 有類似相同的表現 (僅5%的性能落差) Methodology Self-instruct 是一種半自動的過程, 用 LLM 得到的 instruct signal 對 pretrained LM 進行 instruct tuning Step 1: 通常是用人類標註的任務列表當 initial, 利用強 LLM 給定關於產生新任務的 prompt 來產出更多的任務列表 用 LLM 產生新任務的 prompt 範例 12345Come up with a series of tasks:Task 1: Given my personality and the job, tell me if I would be suitable.Task 2: Replace the placeholders in the given text with appropriate named entities.Task 3: Which exercises are best for reducing belly fat at home?Task 4: Step 2: 基於產出的任務列表, 先做二元分類判斷要用哪一種 prompt 後, 再用度強 LLM 來產生 input-output pair 用 LLM 產生二元分類判斷的 prompt 範例 1234Can the following task be regarded as a classification task with finite output labels? Task: Given my personality and the job, tell me if I would be suitable.Is it classification? [Case 1] 用強 LLM 產生分類問題的 input-output pair (output 優先, 避免結果歪掉) 1234567Given the classification task definition and the class labels, generate an input thatcorresponds to each of the class labels. If the task doesn’t require input, just generate thecorrect class label. Task: Classify the sentiment of the sentence into positive, negative, or mixed.Class label: mixedSentence: [Case 2] 用強 LLM 產生非分類問題的 input-output pair (input 優先) 12345Come up with examples for the following tasks. Try to generate multiple examples when possible.If the task doesn’t require additional input, you can generate the output directly. Task: Which exercises are best for reducing belly fat at home?Output: Step 3: 建立一個 Task Pool 作為 instruct tuning 的訓練來源, 並透過各種方法來過濾低質量或重複的 input-output pair 為了保證資料的多樣性, LLM 生成的 input-output pair 會比對 Task Pool 的資料, 若 ROUGE-L(原始資料,新資料) &lt; 0.7 才會被加進 Task Pool 中 為了保證資料的多樣性, 濾除相同 input 但不同 output 的資料 為了保證資料的有用性 (可被 LLM 處理), 濾除包含特定關鍵字 (e.g., images, pictures, graphs) 的 instruct ROUGE-L 指標 Rouge-L 是用來評估自然語言處理系統產生的文本摘要品質的一種評估指標。 Rouge-L 的計算方式是基於最長公共子序列（Longest Common Subsequence, LCS）。 在進行計算時，Rouge-L 將自動將摘要中的單詞轉換為字符，然後使用 LCS 算法計算摘要中的字符與原文中字符的匹配程度，從而得出 Rouge-L 得分。 Step 4: 組裝 input-output pair 成一個 prompt 餵入模型進行 fine tuning, 並給予 prefix 一定的隨機性 A high-level overview of SELF-INSTRUCT Conclusion 此篇論文提出一種&quot;半自動&quot;產生 instruction 的方式, 並透過 LLM 產生訓練資料 也許當時使用的 LLM (text-davinci-001) 不夠強, 使得抽樣 self-instruct 所產出的數據經人工檢查後有高達 46% 的錯誤率 WizardLM 可能強烈受到此篇論文的啟發, 優化了處理資料的方式 GPT (self-instruct) WizardLM instruction 產生方式 text-davinci-001 text-davinci-003 資料過濾方式 ROUGE-L + 滿滿的規則 LLM + 滿滿的規則","tags":["paper study"],"categories":["NLP"]},{"title":"WizardLM - Empowering Large Language Models to Follow Complex Instructions","path":"/2023/05/03/20230502/","content":"本文為 “WizardLM: Empowering Large Language Models to Follow Complex Instructions” (2023.04) 的論文重點摘要 論文全文參考 WizardLM: Empowering Large Language Models to Follow Complex Instructionshttps://arxiv.org/abs/2304.12244 Demo 參考 https://81189ea0b66d14f256.gradio.live/https://81189ea0b66d14f256.gradio.live/ Description Goal 最近的 LLaMA 系列 model 的 instruction 均使用較為普通的 self-instruction 生成方法或是人工生成較簡單的 instruction → 缺乏資料多元性 受到 ChatGPT &amp; GPT4 的啟發, 上述兩模型都經由大量高質量的人工標註保證其資料多元性 → 思考低成本取得高質量的 instruction Contributions 在複雜的 instruction 資料中, 聲稱比 ChatGPT 表現來的好, 這邊有個疑點是沒有一個好的 benchmark 來做評測標準 (僅用 63 筆測試 &amp; 工讀生判定生成的好壞) 複雜指令 WizardLM 勝率比較 在各種難度的 instruction 中, 表現比同種 LLaMA 架構的 Alpaca 和 Vincuna 來得好, 這也驗證了資料多元性或許可以讓模型學習的更好 本文提出一種新的 instruction 產生方式, 有別於一般的 self-instruction, 該 instruction 會衍生出新的複雜分支結果, 作者稱為 “Evol-Instruct” Methodology “Evol-Instruct” 的核心想法是利用原有的簡單 instruction 透過 ChatGPT API 來產生出進階的 instruction 作為模型訓練資料 “Evol-Instruct” 分為兩大類: In-depth Evolving (藍) 和 In-breadth Evolving (紅) In-depth Evolving 又可以分為 5 小類, 底下列出對應的 prompt 生成方式 add constraints Please add one more constraints/requirements into #GivenPrompt# deepening If #Given Prompt# contains inquiries about certain issues, the depth and breadth of the inquiry can be increased concretizing Please replace general concepts with more specific concepts. increase reasoning steps If #GivenPrompt# can be solved with just a few simple thinking processes, you can rewrite it to explicitly request multiple-step reasoning. complicate input You should try your best not to make the #Rewritten Prompt# become verbose, #Rewritten Prompt# can only add 10 to 20 words into #GivenPrompt#. In-breadth Evolving 基於廣度提升 instruction 的複雜度, 底下列出 prompt 生成方式 Your goal is to draw inspiration from the #Given Prompt# to create a brand new prompt. This new prompt should belong to the same domain as the #Given Prompt# but be even more rare. The LENGTH and difficulty level of the #Created Prompt# should be similar to that of the #Given Prompt#. The #Created Prompt# must be reasonable and must be understood and responded by humans. ‘#Given Prompt#’, ‘#Created Prompt#’, ‘given prompt’ and ‘created prompt’ are not allowed to appear in #Created Prompt#. Evol-Instruct Example Elimination Evolving 透過 ChatGPT API 生成的難免會遇到產生失敗的情況, 作者使用以下 4 點來進行過濾 a. 剔除沒有加入額外資訊的 instruction, 方法為透過以下 prompt 打 ChatGPT API 所完成 Here are two Instructions to ChatGPT AI, do you think they are equal to each other,which meet the following requirements: 1.They have same constraints and requirments. 2.They have same depth and breadth of the inquiry. The First Prompt: &lt;Here is first instruction.&gt; The Second Prompt: &lt;Here is second instruction.&gt; Your Judgement (Just answer: Equal or NotEqual. No need to explain the reason.) b. 剔除含有 ‘sorry’ 並且較短的 instruction (少於 80), 這類結果通常代表 ChatGPT API 回答得較為吃力 c. 剔除只包含標點符號和停用詞的 instruction d. 剔除包含一開始設定的 prompt 如 “given prompt”, “rewritten prompt”, “#Rewritten Prompt#” Overview of Evol-Instruct Response Generation: 由於經過 “Evol-Instruct” 後的 instruction 可能與原本問題的答案差距甚大, 作者又去打了一輪 ChatGPT API 作為完整的 QA pair 進行訓練 Conclusion 此篇論文提出一種優化 instruction 的方式, 藉由 ChatGPT API 的改寫能力來取得進階的 instruction 以及對應的 output 作為訓練資料 能夠優於 Alpaca, Vincuna 等近期熱門 model, 可以歸功於工程的成功, 雖然資料取得方式較為暴力, 但要養出一支好的羊駝就必須給好的飼料才能有好的成果","tags":["paper study"],"categories":["NLP"]},{"title":"Vicuna 完整安裝手冊","path":"/2023/05/01/20230501/","content":"本文介紹 Vicuna 模型安裝踩過的一些坑和解法, 實作使用 transformers==4.28.1 Step 1: 下載 LLaMA weight 填寫Meta 申請表格 此方法試過沒成功 使用 pyllama 下載 安裝套件 pip install pyllama -U 下載所有版本(7B, 13B, 30B, 65B)的 LLaMA weight python -m llama.download --model_size 7B,13B,30B,65B --folder ~/pyllama_data 此方法下載的 model 不可用 transformers 來 load, 必須透過 transformers 內建的轉換腳本轉換 python -m transformers.models.llama.convert_llama_weights_to_hf --input_dir ~/ --model_size &#123;13B&#125; --output_dir ~/huggingface_llama_&#123;13B&#125;/ (推薦) 下載別人壓好 huggingface 格式的 model huggingface: decapoda-research/llama-7b-hf Step 2: 加入 Lora 或 Delta weight 主流的方法使採用 LORA 的方式來訓練 weight (Wtarget=Winit+ΔWW_{target}=W_{init}+\\Delta WWtarget​=Winit​+ΔW, 只訓練 ΔW\\Delta WΔW) 轉換 model &amp; 直接 load [LORA] 透過 fastchat 提供的轉換腳本將權重轉換 python -m fastchat.model.apply_lora --base ~/huggingface_llama_&#123;13B&#125;/ --target ~/vicuna_&#123;13B&#125;/ --lora &#123;LORA_MODEL_NAME&#125; [DELTA] 透過 fastchat 提供的轉換腳本將權重轉換 python -m fastchat.model.apply_delta --base ~/huggingface_llama_&#123;13B&#125;/ --target ~/vicuna_&#123;13B&#125;/ --delta lmsys/vicuna-13b-delta-v1.1 載入程式碼如下: 12345678from transformers import LlamaForCausalLM model = LlamaForCausalLM.from_pretrained( &quot;~/vicuna_&#123;13B&#125;&quot;, load_in_8bit=True, device_map=&quot;auto&quot;, torch_dtype=torch.float16) 不轉換直接 load [LORA] 透過 peft 套件來載入, 載入程式碼如下 12345678910111213from transformers import LlamaForCausalLMfrom peft import PeftModel model = LlamaForCausalLM.from_pretrained( &quot;decapoda-research/llama-7b-hf&quot;, device_map=&quot;auto&quot;, torch_dtype=torch.float16)lora_model = PeftModel.from_pretrained(model, LORA_MODEL_NAME, device_map=&#x27;auto&#x27;)model = lora_model.merge_and_unload() [DELTA] 透過 transformers 套件來載入, 載入程式碼如下 1234567891011121314151617181920from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfigmodel = LlamaForCausalLM.from_pretrained( &quot;decapoda-research/llama-7b-hf&quot;, load_in_8bit=False, device_map=&quot;auto&quot;, torch_dtype=torch.float16, low_cpu_mem_usage=True)delta_model = LlamaForCausalLM.from_pretrained( &quot;lmsys/vicuna-7b-delta-v1.1&quot;, load_in_8bit=False, device_map=&quot;auto&quot;, torch_dtype=torch.float16, low_cpu_mem_usage=True)for name, param in model.state_dict().items(): param.data += delta_model.state_dict()[name] Step 3: 預測 GPT 預測原理就是找出下一個字的最高機率值, 但如果每次都使用最高機率值的字會讓結果缺乏多樣性或是讓預測結果歪掉, 所以會建立一套 sampling 機制來處理輸出 next token prediction 常用參數說明: do_sample: 預測結果是否做 sampling, 一般要讓 LLM 具有輸出多樣性都會設定為 True temperature: 控制字詞多元性, 值越高生成結果越有隨機性 temperature 比較 top_k: 保留最大的 k 個字詞作抽樣, 其餘不考慮 top_k 比較 top_p: 保留前 n 個機率值相加&lt; top_p 的字, 用法類似 top_k top_k 比較 repetition_penalty: 懲罰重複出現的字詞 (降低出現機率值) 預測程式碼 12345678910111213141516171819202122232425from transformers import LlamaTokenizertokenizer = LlamaTokenizer.from_pretrained(&quot;lmsys/vicuna-7b-delta-v1.1&quot;)prompt = &quot;台灣小吃淡水阿給是怎麼做的?&quot; inputs = tokenizer(prompt,return_tensors=&quot;pt&quot;)input_ids = inputs[&quot;input_ids&quot;].cuda()generation_config = GenerationConfig( do_sample=False, temperature=0.9, top_p=0.65, num_beams=1, repetition_penalty=1.15 , length_penalty=-0.25)generation_output = model.generate( input_ids=input_ids, generation_config=generation_config, return_dict_in_generate=True, output_scores=True, max_new_tokens=100)print(tokenizer.decode(generation_output.sequences[0])) Reference A step-by-step guide to running Vicuna-13B Large Language Model on your GPU / CPU machine pyllama github LLM hyperparameters LLM hyperparameters","tags":["practice"],"categories":["NLP"]},{"title":"Improving Implicit Sentiment Learning via Local Sentiment Aggregation","path":"/2023/04/11/20230411/","content":"本文為 “Improving Implicit Sentiment Learning via LSA” (2021.10) 的論文重點摘要 論文全文參考 (強烈建議 v1, v2版本一起閱讀) Improving Implicit Sentiment Learning via LSAhttps://arxiv.org/abs/2110.08604 Demo 參考 ABSA Quadruple Extractionhttps://huggingface.co/spaces/Gradio-Blocks/Multilingual-Aspect-Based-Sentiment-Analysis Description Goal 2022年 ABSC 的 SOTA model (SemEval-2014 Task 4 - Subtask 2) ABSA/ABSC 任務 (Aspect Based Sentiment Analysis/Classification) 根據資料集的定義, 這任務又細分為兩類 Aspect term polarity 和 Aspect category polarity Aspect term polarity: 對已經提供的 term 進行情感分類。 Example: I hated their fajitas, but their salads were great → {fajitas: negative, salads: positive} Aspect category polarity: 對抽象概念 aspect 進行情感分類。 Example: The restaurant was too expensive → {price: negative} 此篇論文討論的 ABSC 問題是屬於 Aspect term polarity 類的。 Contributions 非句法樹結構方法優於句法樹(syntax tree)方法。 實驗中比較了數個 syntax-based 的方法在不同的資料集上, 如: SK-GCN-BERT (2020), DGEDT-BERT (2020), ASGCN-RoBERTa (2021), SARL-RoBERTa (2021) 等等。 syntax tree 有個比較大的問題是 syntax 切出來的 token, 會與 BERT token 有 alignment issue。 此篇論文 propose 的方法 LSAT−X−DeBERTaLSA_{T}-X-DeBERTaLSAT​−X−DeBERTa, LSAS−X−DeBERTaLSA_{S}-X-DeBERTaLSAS​−X−DeBERTa 均優於上面 syntax-based 方法約 2-8% 的 F1 score。 (X 代表是 large 模型) syntax tree example LSA (Local Sentiment Aggregation) 是 ABSC 的通用泛式。 實驗中抽換了 pre-train model (BERT, RoBERTa, DeBERTa) 對於結果都有較顯著的改進 0.5%-1%。因此作者認為 LSA 具有一定的擴展性和靈活性。 LSA 是一種通用的架構用來捕捉 aspect 附近的 local sentiment, 分別提取出 aspect feature, 底下會介紹相關細節。 差分加權策略 → 使 LSA 可以用 gradient descent 來優化相鄰情感值。 此策略主要是用在多個 aspect 使用的, 兩個 aspect 中間的子句在計算 aspect feature 時會同時受到影響, 此時就乘上一個 weight ηL\\eta^LηL, ηR\\eta^RηR 來自動訓練出哪個 aspect 影響比較大。 Methodology Sentiment Pattern 作者觀察了五個著名的 ABSC 資料集, 歸納出情感具有 cluster 特性, 因此有了提取相鄰情感的想法 (Sentiment Coherency)。 相鄰情感可以處理更進階的隱式情感, 並可以消除因為部分噪音文字造成的分類錯誤問題。 此例子中有兩個 sentiment cluster Local Sentiment Aggregation (LSA) LSA 使用了 sentiment aggregation window 用來抽取上述的相鄰情感 具體用了三個 local sentiment feature representation LSAPLSA_PLSAP​: BERT-SPC based feature 將 aspect 嵌在句子後面, 利用 BERT 原本就有注意力模組來提取 aspect feature Example: CLS text SEP aspect SEP BERT-SPC based feature LSATLSA_TLSAT​: Local content focus (LCF) based feature 計算 token 和 aspect 的相對距離來獲取 aspect feature 詳細計算方式定義{W1C,W2C,...,WnC}\\{W_1^C,W_2^C,...,W_n^C\\}{W1C​,W2C​,...,WnC​} 為 token 序列HwiCCH^C_{w_i^C}HwiC​C​ (要學的向量) 為每個 token 位置的 hidden statedwiCd_{w_i^C}dwiC​​ (定值) 為 token WiCW_i^CWiC​ 與 aspect 的距離α\\alphaα (超參數) 為距離的 threshold, 通常訂為 3HwiC∗H^*_{w_i^C}HwiC​∗​: aspect feature計算方式token 與 aspect 較近的時候 (dwiC&lt;αd_{w_i^C}&lt;\\alphadwiC​​&lt;α), aspect feature 就是當下的 HwiCCH^C_{w_i^C}HwiC​C​token 與 aspect 較遠的時候 (dwiC≥αd_{w_i^C}\\geq\\alphadwiC​​≥α), aspect feature 會乘距離懲罰項 (1−dwiC−αn)(1-\\frac{d_{w_i^C}-\\alpha}{n})(1−ndwiC​​−α​)dwiCd_{w_i^C}dwiC​​ 距離計算為所有的 aspect 和 token wiCw_i^CwiC​ 平均絕對值距離 LSASLSA_SLSAS​: Syntactical local context focus (LCFS) based feature 距離計算改為 syntax-tree 中每個 token 到 aspect 的最短距離 詳細計算方式計算方式HwiC∗H^*_{w_i^C}HwiC​∗​ 計算方式與 LSATLSA_TLSAT​ 相同dwiC=∑i=jmdist(wiC,wja)md_{w_i^C}=\\frac{\\sum_{i=j}^mdist(w_i^C,w_j^a)}{m}dwiC​​=m∑i=jm​dist(wiC​,wja​)​ Sentiment Aggregation Window Sentiment Aggregation Window 拼接了 aspect 附近的 aspect feature (left, right, text indices) Aggregation Window Padding 拼接的時候會遇到一個狀況是剛好 aspect 位於句子邊界的情況, 作者使用了 copy 的方式做 padding 而非傳統補空值的方法。 Example 無左右兩邊界: [null,Ht,null]\\left[null,H^t,null\\right][null,Ht,null] → [Ht,Ht,Ht]\\left[H^t,H^t,H^t\\right][Ht,Ht,Ht] 無右邊界: [HL,Ht,null]\\left[H^L,H^t,null\\right][HL,Ht,null] → [HL,Ht,Ht]\\left[H^L,H^t,H^t\\right][HL,Ht,Ht] Differential Weighted Aggregation 當有多個 aspect 時, 會遇到共用子句的狀況這時候計算 aspect feature 會有衝突, 這種時候就會用 ηl∗\\eta^*_lηl∗​ 和 ηr∗\\eta^*_rηr∗​ 分別代表左右 aspect feature 的加權值。 Aggregated hidden state Hdwao=[ηl∗{Hkl};Ht;ηr∗{Hkr}]H^o_{dwa}=\\left[\\eta^*_l\\{H^l_k\\};H^t;\\eta_r^*\\{H_k^r\\}\\right] Hdwao​=[ηl∗​{Hkl​};Ht;ηr∗​{Hkr​}] Conclusion 此篇論文提出一個藉由 LSA 的方法來提取 local sentiment, 在多個 dataset 應證此方法的有效性。 在 LSASLSA_SLSAS​ 中使用了 syntax-tree 的架構, 由於上面提到的 token alignment 問題, 作者不建議使用。 此篇論文有個比較不直觀的地方是左右 aspect feature, 作者有實驗了去除和保留的差異, 如下表: Aggregating Window 架構比較","tags":["paper study"],"categories":["NLP"]},{"title":"Deep Natural Language Processing for LinkedIn Search","path":"/2023/04/09/20230409/","content":"本文為 “Deep Natural Language Processing for LinkedIn Search” (2021.08) 的論文重點摘要 論文全文參考 Deep Natural Language Processing for LinkedIn Searchhttps://arxiv.org/abs/2108.13300 Description Goal 討論在搜尋引擎的 5+1 項 NLP 任務實務上的作法 在重視延遲問題的搜尋任務上, 如何導入 BERT 三大挑戰 延遲性：搜尋引擎最重要的問題之一。 穩定性：這邊主要是提到 DL overfit 的問題。 有效性：找出適用各種任務的最佳解法, 可能是 rule base 或 DL model。 Search system overview 大致流程為: User 輸入搜尋句 → 檢查搜尋句完整性 → 判斷搜尋意圖 → 找尋相關候選文章 → 輸出相關候選文章排序 六大搜尋任務 六大任務概覽 Query Intention Prediction Goal: 判斷 User 搜尋的目的是屬於哪一個既有標籤分類 (7類) NLP task: Text Classification Difficulty: 搜尋內容比一般文章來的短造成更嚴重的歧義問題 Example: michael dell (person names), dell engineer jobs (company) Solution (short-term) Method: 使用 TextCNN 的作法, backbone 使用了 GloVe 作為 embedding, 並結合了手工特徵(用戶行為, 文章統計, search log) Finding 不用手工特徵, 準確度掉了 0.4% LSTM 雖然準度有提升 0.2%, 但延遲率較 CNN 增加了 0.5ms CNN based query intent prediction Solution (long-term) Method: 將 backbone 換成 LiBERT (Linkedin BERT) Finding 準確度較 CNN 提升了 3.28%, 但沒有比較延遲率的結果 Query Tagging Goal: 抓出 query 中包含的 entity NLP task: NER Difficulty: entity 有嵌套以及歧異的問題 Example: research scientist (title), research (skill), scientist (title) Solution Feature: 分為 char based, word based, lexicon base Method: 使用 semi-markov conditional random f ield (SCRF) Finding: 由於 query 本身已經很短了, 還要再從中抽取 entity 導致大多 DL 模型效果不如建立辭典的方式 (lexicon) Document Ranking Goal: 給定 Query, 從一堆文章找出相關度排序 NLP task: Semantic Textual Similarity Difficulty: 延遲性 &amp; 持續有效性 Solution Method Step 1: 提取 Query 和一份文檔有多個區塊 embedding Step 2: 計算 Query embedding 和各區塊 embedding 的 cos similarity Step 3: 將 cos 特徵和手工特徵 concat 起來 Step 4: 建立 learning-to-rank layer 來計算此文檔的分數 模型架構 (不包含 learning-to-rank layer) Supplementary learning-to-rank layer Reference：Neural Ranking Models with Multiple Document Fields Sign: Ψ\\PsiΨ : matching netword ΛD\\Lambda_DΛD​ : 集成 D 文檔的各區塊 ΦQ\\Phi_QΦQ​ : query representation ΦD\\Phi_DΦD​ : doc representation ΦF\\Phi_FΦF​ : D 文檔的各個 field representation DDD 文檔的檢索分數 Ψ(ΦQ,ΦD)=Ψ(ΦQ,ΛD(ΦF1(F1),ΦF2(F2),...,ΦFk(Fk)))\\Psi(\\Phi_Q,\\Phi_D)=\\Psi(\\Phi_Q,\\Lambda_D(\\Phi_{F1}(F1),\\Phi_{F2}(F2),...,\\Phi_{Fk}(Fk))) Ψ(ΦQ​,ΦD​)=Ψ(ΦQ​,ΛD​(ΦF1​(F1),ΦF2​(F2),...,ΦFk​(Fk))) ranking model 架構 Finding: 手工特徵是在個任務的實驗上屬於強力特徵。個人抱持懷疑的態度，畢竟驗證指標使用的是 NDCG, 而非衡量文章相似度作為指標。 Query Auto Completion Goal: 在 user 輸入關鍵字的時, 同時推薦可能想輸入的候選字 NLP task: Language Generation Difficulty: 延遲性 Solution Candidate Generation 對於過往出現過的關鍵詞, 可以用記憶體存取的方式直接讀取 對於未出現的關鍵詞, 採用啟發式的方式產生候選字 啟發式結果可以從三個方式去得 一定時間內, 同個 session 接續查詢的 query (水平) 同用戶輸入的兩個 query 有 co-word (垂直) 不同用戶兩個 query 同時出現 Reference: Mitra and Craswell (2015) Candidate Ranking LSTM 計算後面要接龍字的分數值 query auto completion 架構 (不包含 learning-to-rank layer) Query Suggestion Goal: 在搜尋結束時, 給予 user 下個搜尋字推薦, 類似推薦文章的想法 NLP task: Machine Translation (Seq2Seq) Difficulty: 延遲性, 穩定性 Solution seq2seq model Finding 此任務也可以用來做 query rewrite, 也許可以避免一些 user query 的冷門字 Example: software developer → software engineer BERT Pretrained Goal: 訓練基於自己 domain 的 BERT model NLP task: Eembedding Difficulty: 延遲性 Solution 收集自有的 domain data 使用輕量的 BERT 架構 (12層 → 6層), 以利加快推論速度 Conclusion 依據任務 &amp; 資料特性決定要使用甚麼樣的 model, 不一定都要套用 DL model 文中指出在 Query Tagging 和 Query Auto Completion (seen) 上 DL model 沒有 benefit 對於延遲性的建議 重新設計算法 (e.g., query auto completion) 平行計算 (e.g., query suggestion) Embedding pre-sum (e.g., document ranking) Two stage ranking (e.g., document ranking) 對於穩定性的建議 Check training data, 剔除高度相似的資料 Reuse 手工特徵, 這邊指的是避免過度依賴文字相關的結果","tags":["paper study"],"categories":["NLP"]},{"title":"Meta Segment Anything","path":"/2023/04/08/20230408/","content":"本文介紹 Meta FAIR 新出的套件 segment-anything 的實作方法 &amp; 結果 Demo 網站 https://segment-anything.com/https://segment-anything.com/ Description Goal 自動化 segment 任務 (zero shot), 並可以根據 prompt (point, box, text) 進行調整 Data SA-1B: 高達 11M 張圖片, 1.1B 個 mask 結果 (由 SAM 生成) Result 僅實驗自動化切割功能, 文字 prompt 功能未釋出 插畫自動切割 左圖：原圖 中圖：部分星星沒有被切割出來是因為有設定 threshold 來避免切出太小的物件, 共 109 個區域 右圖：挑選最大面積的 6 個物件顯示 圖片來源: midjourney 產生 Wafer Map 自動切割 左圖：原圖 中圖：部分文字沒有被切割出來是因為有設定 threshold 來避免切出太小的物件, 共 147 個區域 右圖：挑選最大面積的 4 個物件顯示 圖片來源: Development of High Power Green Light Emitting Diode Chips paper SEM Image 自動切割 左圖：原圖 中圖：部分文字沒有被切割出來是因為有設定 threshold 來避免切出太小的物件, 共 32 個區域 右圖：挑選除了 Top1 以外的物件 圖片來源: DLADC: Deep Learning Based Semiconductor Wafer Surface Defects Recognition paper Model Architecture 圖片來源: segment-anything paper Practice Step 1: 模型下載 SAM model 下載 download, 放入 model 資料夾中 123mkdir modelcd modelwget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth Step 2: 讀入權重 import 相關套件 &amp; load model weight 12345678from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictorsam_checkpoint = &quot;./model/sam_vit_h_4b8939.pth&quot;model_type = &quot;vit_h&quot;device = &quot;cuda&quot;sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)sam.to(device=device) Step 3: 載入圖片 用 cv2 載入圖片並轉為 array 形式 123import cv2image = cv2.imread(&#x27;./data/test.png&#x27;)image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) Step 4: 設定模型參數 &amp; 預測 套用 mask 生成器並設定相關參數, 實作後認為 points_per_side, pred_iou_thresh 較為重要。 points_per_side 是控制採樣點的個數, 直接影響到輸出 mask 的質量 pred_iou_thresh 是輸出 mask 機率的 threshold 輸出結果包含了每個 mask 結果的面積大小, bounding box, mask 座標等等。 12345678910mask_generator = SamAutomaticMaskGenerator( model=sam, points_per_side=32, pred_iou_thresh=0.9, stability_score_thresh=0.92, crop_n_layers=1, crop_n_points_downscale_factor=2, min_mask_region_area=100, # Requires open-cv to run post-processing)masks2 = mask_generator.generate(image) Step 5: 顯示分割結果 依照 mask 面積大小排序對原圖進行 mask 著色 12345678910111213141516171819202122import numpy as npimport matplotlib.pyplot as pltdef show_anns(anns): if len(anns) == 0: return sorted_anns = sorted(anns, key=(lambda x: x[&#x27;area&#x27;]), reverse=True) ax = plt.gca() ax.set_autoscale_on(False) for ann in sorted_anns: m = ann[&#x27;segmentation&#x27;] img = np.ones((m.shape[0], m.shape[1], 3)) color_mask = np.random.random((1, 3)).tolist()[0] for i in range(3): img[:,:,i] = color_mask[i] ax.imshow(np.dstack((img, m*0.35)))plt.figure(figsize=(15,15))plt.imshow(image)show_anns(masks2)plt.axis(&#x27;off&#x27;)plt.show() Step 6: 去背結果 建立一個 mask matrix 在乘上原本圖片 matrix 後, 即可得到去背的圖片 123456789101112final_mask = np.zeros(image.shape[:2],dtype=bool)for i in range(len(masks2)): final_mask +=masks2[i][&#x27;segmentation&#x27;]mask_image = image.copy()for i in range(3): mask_image[:,:,i] *=final_maskplt.figure(figsize=(15,15))plt.imshow(mask_image)plt.axis(&#x27;off&#x27;)plt.show()","tags":["practice","Meta"],"categories":["CV"]},{"title":"LLaMA 套件踩坑","path":"/2023/04/07/20230407/","content":"本文介紹 LLaMA 系列套件安裝踩過的一些坑和解法 更新紀錄 2023/05/05: 更新 transformer 相依性問題, llama.cpp 採坑紀錄 bitsandbytes load_in_8bit error Root Cause: 系統預設的 bitsandbytes_cpu.so 與 cuda 版本不同 Action: 將自己的版本的 bitsandbytes_cuda&lt;cuda版號&gt;.so 替換為 bitsandbytes_cpu.so step1: mv lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cpu.so lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cuda114.so step2: cp lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cuda117.so lib/python3.9/site-packages/bitsandbytes/lib/bitsandbytes_cpu.so transformer transformers 需要更新到 4.28.0 以上的版本。 目前僅有 transformers-main 的版本支援 LlamaTokenizer 系列的子套件 llama.cpp 一個以 C++ 進行編譯並支援 LLM model 轉換 &amp; 壓縮成 CPU 推論版的套件。 (Github) 詳細壓縮和量化方法參考這裡 python 相關支援參考這裡 不管是 python 版還是 C++ 版，系統的 GCC 版本都需要升級到 9 以上, ubuntu 參考以下指令進行升級 12345678sudo apt install -y software-properties-commonsudo add-apt-repository -y ppa:ubuntu-toolchain-r/testsudo apt updatesudo apt install -y gcc-9 g++-9sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 60sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 60sudo update-alternatives --config gccsudo update-alternatives --config g++ pytorch docker LLaMA 最低 python 環境要求為 python 3.8, 如何的套用現成 Docker Image? 以下是 pytorch 在 dockerhub 各版本對應到的 python 環境:","tags":["practice"],"categories":["NLP"]},{"path":"/about/index.html","content":"About Me 一位誤入動物園的 NLP 新手, 專長是販賣各種動物周邊 (NLP 建模) 和 Boost 系列跑鞋 (ML 建模)。 Job Experiment Now AI Engineer at TSMCDefect Report 自動化知識抽取2022 年 6 月 Machine Learning Engineer at Invos既有產品品類多標籤分類模型新品牌、新品類自動化挖掘模型2022 年 3 月 Senior Data Scientist at Wisers專利發表新詞發現算法⾏業專業詞挖掘算法商用 API 開發關鍵詞抽取模組 (包含新詞、熱詞、領域關鍵詞)通用型購買意願模型 (包含中文、廣東話)評論分類模型英文情感分析模型技術研發自動化 POC tagging (支援 8 個 API, 14 種客製化抽取算法)運動品牌知識圖譜優化特定實體的購買意願模型2020 年 2 月 Data Scientist at GSSVital CRM Insight 產品維護 &amp; 新功能開發行銷最佳化 BI公司級產品關鍵字廣告成效分析2019 年 7 月"},{"path":"/notes/index.html","content":"項目 競賽 2022 玉山人工智慧挑戰賽 - 你說可疑不可疑？ 疑似洗錢交易預測 https://github.com/ansonchang/esun2022https://github.com/ansonchang/esun2022 2021 中鋼人工智慧挑戰賽 - 字元辨識 https://github.com/yifor01/CSC-OCR-competitionhttps://github.com/yifor01/CSC-OCR-competition 2020 I'm the Best Coder Challenge! 2020 https://github.com/yifor01/High-Value-Customer-Forecast-Competitionhttps://github.com/yifor01/High-Value-Customer-Forecast-Competition"}]