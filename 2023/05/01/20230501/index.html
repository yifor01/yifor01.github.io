<!DOCTYPE html>
<html lang='zh-TW'>

<head>
  <meta name="generator" content="Hexo 6.3.0">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.18.5">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://gcore.jsdelivr.net'>
  <link rel="preconnect" href="https://gcore.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>Vicuna å®Œæ•´å®‰è£æ‰‹å†Š - Yifor Note</title>

  
    <meta name="description" content="æœ¬æ–‡ä»‹ç´¹ Vicuna æ¨¡å‹å®‰è£è¸©éçš„ä¸€äº›å‘å’Œè§£æ³•, å¯¦ä½œä½¿ç”¨ transformers&#x3D;&#x3D;4.28.1 Step 1: ä¸‹è¼‰ LLaMA weight  å¡«å¯«Meta ç”³è«‹è¡¨æ ¼  æ­¤æ–¹æ³•è©¦éæ²’æˆåŠŸ   ä½¿ç”¨ pyllama ä¸‹è¼‰  å®‰è£å¥—ä»¶ pip install pyllama -U ä¸‹è¼‰æ‰€æœ‰ç‰ˆæœ¬(7B, 13B, 30B, 65B)çš„ LLaMA weight python -m llama">
<meta property="og:type" content="article">
<meta property="og:title" content="Vicuna å®Œæ•´å®‰è£æ‰‹å†Š">
<meta property="og:url" content="http://example.com/2023/05/01/20230501/index.html">
<meta property="og:site_name" content="Yifor Note">
<meta property="og:description" content="æœ¬æ–‡ä»‹ç´¹ Vicuna æ¨¡å‹å®‰è£è¸©éçš„ä¸€äº›å‘å’Œè§£æ³•, å¯¦ä½œä½¿ç”¨ transformers&#x3D;&#x3D;4.28.1 Step 1: ä¸‹è¼‰ LLaMA weight  å¡«å¯«Meta ç”³è«‹è¡¨æ ¼  æ­¤æ–¹æ³•è©¦éæ²’æˆåŠŸ   ä½¿ç”¨ pyllama ä¸‹è¼‰  å®‰è£å¥—ä»¶ pip install pyllama -U ä¸‹è¼‰æ‰€æœ‰ç‰ˆæœ¬(7B, 13B, 30B, 65B)çš„ LLaMA weight python -m llama">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://i.imgur.com/Rep1rNX.png">
<meta property="og:image" content="https://i.imgur.com/AXap0TG.png">
<meta property="og:image" content="https://i.imgur.com/ACrI95m.png">
<meta property="og:image" content="https://i.imgur.com/RLZ6JFP.png">
<meta property="article:published_time" content="2023-05-01T12:35:55.000Z">
<meta property="article:modified_time" content="2023-05-01T15:12:04.388Z">
<meta property="article:author" content="Howard Chang">
<meta property="article:tag" content="practice">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://i.imgur.com/Rep1rNX.png">
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  
    <link rel="shortcut icon" href="https://i.imgur.com/kcnNk0y.png">
  

  

  


  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    

  

<header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.4/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="https://i.imgur.com/bIQxvby.jpg" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.4/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title">Yifor Note</div><div class="sub normal cap">ğŸ”† è®€æ›¸ç­†è¨˜</div><div class="sub hover cap" style="opacity:0"> ğŸ”†Written from Howard</div></a></div>

<nav class="menu dis-select"><a class="nav-item active" href="/">Blog</a><a class="nav-item" href="/notes/">é …ç›®</a><a class="nav-item" href="/about/">é—œæ–¼</a></nav>
</header>


<div class="widgets">
<widget class="widget-wrapper search"><div class="widget-body"><div class="search-wrapper" id="search"><form class="search-form"><input type="text" class="search-input" id="search-input" data-filter="/blog/" placeholder="æ–‡ç« æœç´¢"><svg t="1670596976048" class="icon search-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2676" width="200" height="200"><path d="M938.2 832.6L723.8 618.1c-2.5-2.5-5.3-4.4-7.9-6.4 36.2-55.6 57.3-121.8 57.3-193.1C773.3 222.8 614.6 64 418.7 64S64 222.8 64 418.6c0 195.9 158.8 354.6 354.6 354.6 71.3 0 137.5-21.2 193.2-57.4 2 2.7 3.9 5.4 6.3 7.8L832.5 938c14.6 14.6 33.7 21.9 52.8 21.9 19.1 0 38.2-7.3 52.8-21.8 29.2-29.1 29.2-76.4 0.1-105.5M418.7 661.3C284.9 661.3 176 552.4 176 418.6 176 284.9 284.9 176 418.7 176c133.8 0 242.6 108.9 242.6 242.7 0 133.7-108.9 242.6-242.6 242.6" p-id="2677"></path></svg></form><div id="search-result"></div><div class="search-no-result">æ²’æœ‰æ‰¾åˆ°å…§å®¹ï¼</div></div></div></widget>


<widget class="widget-wrapper toc single" id="data-toc"><div class="widget-header cap dis-select"><span class="name">Vicuna å®Œæ•´å®‰è£æ‰‹å†Š</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-1-%E4%B8%8B%E8%BC%89-LLaMA-weight"><span class="toc-text">Step 1: ä¸‹è¼‰ LLaMA weight</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-2-%E5%8A%A0%E5%85%A5-lora-%E6%88%96-delta-weight"><span class="toc-text">Step 2: åŠ å…¥ lora æˆ– delta weight</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Step-3-%E9%A0%90%E6%B8%AC"><span class="toc-text">Step 3: é æ¸¬</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-text">Reference</span></a></li></ol></div></div></widget>




</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" href="https://github.com/yifor01" target="_blank" rel="external nofollow noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn-icons-png.flaticon.com/128/3291/3291695.png"/></a><a class="social" href="https://www.linkedin.com/in/chia-hao-chang-yifor" target="_blank" rel="external nofollow noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn-icons-png.flaticon.com/512/174/174857.png"/></a></div></footer>

    </aside>
    <div class='l_main'>
      

      


<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">é¦–é </a><span class="sep"></span><a class="cap breadcrumb" href="/">ç¶²èªŒ</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/NLP/">NLP</a></div><div id="post-meta">ç™¼å¸ƒæ–¼&nbsp;<time datetime="2023-05-01T12:35:55.000Z">2023-05-01</time></div></div>

<article class='md-text content post'>
<h1 class="article-title"><span>Vicuna å®Œæ•´å®‰è£æ‰‹å†Š</span></h1>
<p>æœ¬æ–‡ä»‹ç´¹ Vicuna æ¨¡å‹å®‰è£è¸©éçš„ä¸€äº›å‘å’Œè§£æ³•, å¯¦ä½œä½¿ç”¨ <code>transformers==4.28.1</code></p>
<h2 id="Step-1-ä¸‹è¼‰-LLaMA-weight">Step 1: ä¸‹è¼‰ LLaMA weight</h2>
<ol>
<li>å¡«å¯«<a target="_blank" rel="noopener" href="https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform">Meta ç”³è«‹è¡¨æ ¼</a>
<ul>
<li>æ­¤æ–¹æ³•è©¦éæ²’æˆåŠŸ</li>
</ul>
</li>
<li>ä½¿ç”¨ <code>pyllama</code> ä¸‹è¼‰
<ul>
<li>å®‰è£å¥—ä»¶ <code>pip install pyllama -U</code></li>
<li>ä¸‹è¼‰æ‰€æœ‰ç‰ˆæœ¬(7B, 13B, 30B, 65B)çš„ LLaMA weight<br>
<code>python -m llama.download --model_size 7B,13B,30B,65B --folder ~/pyllama_data</code></li>
<li>æ­¤æ–¹æ³•çš„ model ä¸å¯ç”¨ <code>transformers</code> æ–¹æ³•ä¾† load, å¿…é ˆé€é <code>transformers</code> å…§å»ºçš„è½‰æ›è…³æœ¬è½‰æ›<br>
<code>python -m transformers.models.llama.convert_llama_weights_to_hf --input_dir ~/ --model_size &#123;13B&#125; --output_dir ~/huggingface_llama_&#123;13B&#125;/</code></li>
</ul>
</li>
<li>(æ¨è–¦) ä¸‹è¼‰åˆ¥äººå£“å¥½ huggingface æ ¼å¼çš„ model
<ul>
<li>huggingface: <a target="_blank" rel="noopener" href="https://huggingface.co/decapoda-research/llama-7b-hf">decapoda-research/llama-7b-hf</a></li>
</ul>
</li>
</ol>
<h2 id="Step-2-åŠ å…¥-lora-æˆ–-delta-weight">Step 2: åŠ å…¥ lora æˆ– delta weight</h2>
<ul>
<li>ä¸»æµçš„æ–¹æ³•ä½¿æ¡ç”¨ LORA çš„æ–¹å¼ä¾†è¨“ç·´ weight ($W_{target}=W_{init}+\Delta W$, åªè¨“ç·´ $\Delta W$)</li>
</ul>
<ol>
<li>
<p>é€é <a target="_blank" rel="noopener" href="https://github.com/lm-sys/FastChat#vicuna-weights">fastchat</a> æä¾›çš„è½‰æ›è…³æœ¬å°‡æ¬Šé‡è½‰æ›<br>
<code>python -m fastchat.model.apply_delta --base ~/huggingface_llama_&#123;13B&#125;/ --target ~/vicuna_&#123;13B&#125;/ --delta lmsys/vicuna-13b-delta-v1.1</code></p>
<p>è¼‰å…¥ç¨‹å¼ç¢¼å¦‚ä¸‹:</p>
   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from transformers import LlamaForCausalLM</span><br><span class="line">    </span><br><span class="line">model = LlamaForCausalLM.from_pretrained(</span><br><span class="line">    &quot;~/vicuna_&#123;13B&#125;&quot;,</span><br><span class="line">    load_in_8bit=True,</span><br><span class="line">    device_map=&quot;auto&quot;,</span><br><span class="line">    torch_dtype=torch.float16</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>è‹¥ç‚º LORA MODEL, é€é <a target="_blank" rel="noopener" href="https://github.com/huggingface/peft">peft</a> å¥—ä»¶ä¾†è¼‰å…¥, è¼‰å…¥ç¨‹å¼ç¢¼å¦‚ä¸‹</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> LlamaForCausalLM</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftModel</span><br><span class="line">    </span><br><span class="line">model = LlamaForCausalLM.from_pretrained(</span><br><span class="line">    <span class="string">&quot;decapoda-research/llama-7b-hf&quot;</span>,</span><br><span class="line">    device_map=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    torch_dtype=torch.float16</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">lora_model = PeftModel.from_pretrained(model, </span><br><span class="line">                                       LORA_MODEL_NAME, </span><br><span class="line">                                       device_map=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line">model = lora_model.merge_and_unload()</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>è‹¥ç‚º DELTA MODEL, é€é <code>transformers</code> å¥—ä»¶ä¾†è¼‰å…¥, è¼‰å…¥ç¨‹å¼ç¢¼å¦‚ä¸‹</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> LlamaTokenizer, LlamaForCausalLM, GenerationConfig</span><br><span class="line"></span><br><span class="line">model = LlamaForCausalLM.from_pretrained(</span><br><span class="line">    <span class="string">&quot;decapoda-research/llama-7b-hf&quot;</span>,</span><br><span class="line">    load_in_8bit=<span class="literal">False</span>,</span><br><span class="line">    device_map=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    torch_dtype=torch.float16,</span><br><span class="line">    low_cpu_mem_usage=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">delta_model = LlamaForCausalLM.from_pretrained(</span><br><span class="line">    <span class="string">&quot;lmsys/vicuna-7b-delta-v1.1&quot;</span>,</span><br><span class="line">    load_in_8bit=<span class="literal">False</span>,</span><br><span class="line">    device_map=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    torch_dtype=torch.float16,</span><br><span class="line">    low_cpu_mem_usage=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">   </span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.state_dict().items():</span><br><span class="line">    param.data += delta_model.state_dict()[name]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Step-3-é æ¸¬">Step 3: é æ¸¬</h2>
<ul>
<li>
<p>GPT é æ¸¬åŸç†å°±æ˜¯æ‰¾å‡ºä¸‹ä¸€å€‹å­—çš„æœ€é«˜æ©Ÿç‡å€¼, ä½†å¦‚æœæ¯æ¬¡éƒ½ä½¿ç”¨æœ€é«˜æ©Ÿç‡å€¼çš„å­—æœƒè®“çµæœç¼ºä¹å¤šæ¨£æ€§æˆ–æ˜¯è®“é æ¸¬çµæœæ­ªæ‰, æ‰€ä»¥æœƒå»ºç«‹ä¸€å¥— sampling æ©Ÿåˆ¶ä¾†è™•ç†è¼¸å‡º</p>
  <div class="tag-plugin image"><div class="image-bg"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://i.imgur.com/Rep1rNX.png" alt="next token prediction" fancybox="true" style="height:400px;"/></div><div class="image-meta"><span class="image-caption center">next token prediction</span></div></div>
</li>
<li>
<p>å¸¸ç”¨åƒæ•¸èªªæ˜:</p>
<ul>
<li>do_sample: é æ¸¬çµæœæ˜¯å¦åš sampling, ä¸€èˆ¬è¦è®“ LLM å…·æœ‰è¼¸å‡ºå¤šæ¨£æ€§éƒ½æœƒè¨­å®šç‚º True</li>
<li>temperature: æ§åˆ¶å­—è©å¤šå…ƒæ€§, å€¼è¶Šé«˜ç”Ÿæˆçµæœè¶Šæœ‰éš¨æ©Ÿæ€§</li>
</ul>
  <div class="tag-plugin image"><div class="image-bg"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://i.imgur.com/AXap0TG.png" alt="temperature æ¯”è¼ƒ" fancybox="true" style="width:400px;"/></div><div class="image-meta"><span class="image-caption center">temperature æ¯”è¼ƒ</span></div></div>
<ul>
<li>top_k: ä¿ç•™æœ€å¤§çš„ k å€‹å­—è©ä½œæŠ½æ¨£, å…¶é¤˜ä¸è€ƒæ…®</li>
</ul>
  <div class="tag-plugin image"><div class="image-bg"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://i.imgur.com/ACrI95m.png" alt="top_k æ¯”è¼ƒ" fancybox="true" style="width:600px;"/></div><div class="image-meta"><span class="image-caption center">top_k æ¯”è¼ƒ</span></div></div>
<ul>
<li>top_p: ä¿ç•™å‰ n å€‹æ©Ÿç‡å€¼ç›¸åŠ &lt; top_p çš„å­—, ç”¨æ³•é¡ä¼¼ top_k</li>
</ul>
  <div class="tag-plugin image"><div class="image-bg"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://i.imgur.com/RLZ6JFP.png" alt="top_k æ¯”è¼ƒ" fancybox="true" style="width:600px;"/></div><div class="image-meta"><span class="image-caption center">top_k æ¯”è¼ƒ</span></div></div>
<ul>
<li>repetition_penalty: æ‡²ç½°é‡è¤‡å‡ºç¾çš„å­—è© (é™ä½å‡ºç¾æ©Ÿç‡å€¼)</li>
</ul>
</li>
<li>
<p>é æ¸¬ç¨‹å¼ç¢¼</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = LlamaTokenizer.from_pretrained(<span class="string">&quot;lmsys/vicuna-7b-delta-v1.1&quot;</span>)</span><br><span class="line">prompt = <span class="string">&quot;å°ç£å°åƒæ·¡æ°´é˜¿çµ¦æ˜¯æ€éº¼åšçš„?&quot;</span> </span><br><span class="line">inputs = tokenizer(prompt,return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">input_ids = inputs[<span class="string">&quot;input_ids&quot;</span>].cuda()</span><br><span class="line"></span><br><span class="line">generation_config = GenerationConfig(</span><br><span class="line">    do_sample=<span class="literal">False</span>,</span><br><span class="line">    temperature=<span class="number">0.9</span>,</span><br><span class="line">    top_p=<span class="number">0.65</span>,</span><br><span class="line">    num_beams=<span class="number">1</span>,</span><br><span class="line">    repetition_penalty=<span class="number">1.15</span> ,</span><br><span class="line">    length_penalty=-<span class="number">0.25</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">generation_output = model.generate(</span><br><span class="line">    input_ids=input_ids,</span><br><span class="line">    generation_config=generation_config,</span><br><span class="line">    return_dict_in_generate=<span class="literal">True</span>,</span><br><span class="line">    output_scores=<span class="literal">True</span>,</span><br><span class="line">    max_new_tokens=<span class="number">100</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tokenizer.decode(generation_output.sequences[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Reference">Reference</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.linkedin.com/pulse/step-by-step-guide-running-vicuna-13b-large-language-nischal/">A step-by-step guide to running Vicuna-13B Large Language Model on your GPU / CPU machine</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/juncongmoo/pyllama">pyllama github</a></li>
<li><a target="_blank" rel="noopener" href="https://learnprompting.org/docs/basics/configuration_hyperparameters">LLM hyperparameters</a></li>
<li><a target="_blank" rel="noopener" href="https://txt.cohere.com/llm-parameters-best-outputs-language-ai/">LLM hyperparameters</a></li>
</ul>




</article>

<div class="related-wrap reveal" id="read-next"><section class="body"><div class="item" id="prev"></div><div class="item" id="next"><div class="note">è¼ƒæ—©æ–‡ç« </div><a href="/2023/04/11/20230411/">Improving Implicit Sentiment Learning via Local Sentiment Aggregation</a></div></section></div>






  <div class='related-wrap md-text reveal' id="comments">
    <section class='header cmt-title cap theme'>
      åƒèˆ‡è¨è«–
    </section>
    <section class='body cmt-body giscus'>
      

<svg class="loading" style="vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="giscus" data-repo="yifor01/blog-comments" data-repo-id="R_kgDOJUQBwQ" data-category="General" data-category-id="DIC_kwDOJUQBwc4CVoZ6" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="preferred_color_scheme" data-lang="zh-TW" data-loading="lazy" crossorigin="anonymous"></div>

    </section>
  </div>



      
<footer class="page-footer reveal fs12"><hr><div class="text"><center>
</br>
</br>
  <!--ä¸è’œå­è¨ˆæ•¸å™¨-->
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <!--æ·»åŠ ä¸€å€‹è¨ªå•é‡-->
  <span>
  æœ¬"<span style="color: rgb(13, 109, 252); font-weight: bold;">é é¢</ a></span>"è¨ªå• <span id="busuanzi_value_page_pv" style="color: rgb(13, 109, 252); font-weight: bold;"></span> æ¬¡
  | ğŸ‘€ç¸½è¨ªå• <span id="busuanzi_value_site_pv" style="color: rgb(13, 109, 252); font-weight: bold;"></span> æ¬¡
  | ğŸç¸½è¨ªå®¢ <span id="busuanzi_value_site_uv" style="color: rgb(13, 109, 252); font-weight: bold;"></span> äºº
  </span>
  </br>
  </br>
  <script type="text/javascript">
  function show_runtime() {
      window.setTimeout("show_runtime()", 1000);
      X = new Date("4/07/2023 00:00:00");
      Y = new Date();
      T = (Y.getTime() - X.getTime());
      M = 24 * 60 * 60 * 1000;
      a = T / M;
      A = Math.floor(a);
      b = (a - A) * 24;
      B = Math.floor(b);
      c = (b - B) * 60;
      C = Math.floor((b - B) * 60);
      D = Math.floor((c - C) * 60);
      runtime_span.innerHTML = "â±ï¸æœ¬ç«™å·²é‹è¡Œ " + A + "å¤© " + B + "å°æ™‚ " + C + "åˆ† " + D + "ç§’"
  }
  show_runtime();
  </script>
  <span id="runtime_span"></span>
</center>
<hr>
<p>æœ¬ç«™ç”± <a href="/">@yifor</a> ä½¿ç”¨ <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a> ä¸»é¡Œå‰µå»ºã€‚<br>
æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥è²æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> è¨±å¯å”è­°ï¼Œè½‰è¼‰è«‹æ³¨æ˜å‡ºè™•ã€‚</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  const stellar = {
    // æ‡’åŠ è½½ css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // ä» butterfly å’Œ volantis è·å¾—çµæ„Ÿ
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // é»˜è®¤å¼‚æ­¥ï¼Œå¦‚æœéœ€è¦åŒæ­¥ï¼Œç¬¬äºŒä¸ªå‚æ•°ä¼ å…¥ {} å³å¯
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.version = '1.18.5';
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.18.5';
  stellar.config = {
    date_suffix: {
      just: 'å‰›å‰›',
      min: 'åˆ†é˜å‰',
      hour: 'å°æ™‚å‰',
      day: 'å¤©å‰',
      month: 'å€‹æœˆå‰',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://gcore.jsdelivr.net/npm/jquery@3.6.2/dist/jquery.min.js'
  };

  if ('local_search') {
    stellar.search = {};
    stellar.search.service = 'local_search';
    if (stellar.search.service == 'local_search') {
      let service_obj = Object.assign({}, {"field":"all","path":"/search.json","content":true,"sort":"-date"});
      stellar.search[stellar.search.service] = service_obj;
    }
  }

  // stellar js
  stellar.plugins.stellar = Object.assign({"sites":"/js/plugins/sites.js","friends":"/js/plugins/friends.js","ghinfo":"/js/plugins/ghinfo.js","timeline":"/js/plugins/timeline.js","linkcard":"/js/plugins/linkcard.js","fcircle":"/js/plugins/fcircle.js","weibo":"/js/plugins/weibo.js"});

  stellar.plugins.marked = Object.assign("https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js");
  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/vanilla-lazyload@17.8.3/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.css","js":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://gcore.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://gcore.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://gcore.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti@0.9.2/umd/heti.min.css","js":"https://unpkg.com/heti@0.9.2/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->

  <script>
  function loadJS() {
    const els = document.querySelectorAll("#comments #giscus");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.log(error);
      }
      var script = document.createElement('script');
      script.src = 'https://giscus.app/client.js';
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  }
  window.addEventListener('DOMContentLoaded', (event) => {
    loadJS();
  });
</script>




<!-- inject -->


  </div>
</body>
</html>
